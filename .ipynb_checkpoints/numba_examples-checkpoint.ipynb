{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/evaneschneider/parallel-programming/blob/master/numba_examples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TZnDVfZW2Ju1"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "UfIRoGRi0oIN",
    "outputId": "af5ef3b1-7c97-49f0-e1c1-f2bdce04f2cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed (with compilation) = 0.5545870500000021\n",
      "Elapsed (after compilation) = 5.390100000113307e-05\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(100).reshape(10, 10)\n",
    "\n",
    "@jit(nopython=True)\n",
    "def go_fast(a): # Function is compiled and runs in machine code\n",
    "    trace = 0\n",
    "    for i in range(a.shape[0]):\n",
    "        trace += np.tanh(a[i, i])\n",
    "    return a + trace\n",
    "\n",
    "# DO NOT REPORT THIS... COMPILATION TIME IS INCLUDED IN THE EXECUTION TIME!\n",
    "start = timer()\n",
    "go_fast(x)\n",
    "end = timer()\n",
    "print(\"Elapsed (with compilation) = %s\" % (end - start))\n",
    "\n",
    "# NOW THE FUNCTION IS COMPILED, RE-TIME IT EXECUTING FROM CACHE\n",
    "start = timer()\n",
    "go_fast(x)\n",
    "end = timer()\n",
    "print(\"Elapsed (after compilation) = %s\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "MEftAmVzVRTn",
    "outputId": "e96c60d0-207d-4290-8a6c-22aba3caf646"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413 ns ± 6.25 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "424 ns ± 3.32 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "from numba import vectorize, int32, float64\n",
    "\n",
    "a_int = np.arange(10, dtype=np.int32)\n",
    "a_double = np.arange(10, dtype=np.float64)\n",
    "\n",
    "@vectorize([int32(int32, int32)])\n",
    "def f_int(x, y):\n",
    "    return x + y\n",
    "  \n",
    "@vectorize([float64(float64, float64)])\n",
    "def f_double(x, y):\n",
    "    return x + y\n",
    "\n",
    "%timeit f_int(a_int, a_int)\n",
    "%timeit f_double(a_double, a_double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i4j6CB6HeBMY"
   },
   "outputs": [],
   "source": [
    "from numba import cfunc\n",
    "\n",
    "def integrand(t):\n",
    "  return np.exp(-t) / t**2\n",
    "\n",
    "nb_integrand = cfunc(\"float64(float64)\")(integrand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "coTFnsREeVDU",
    "outputId": "f422fc3c-e012-4362-9c9e-031da1de9188"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 µs ± 3.73 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "28.1 µs ± 702 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "import scipy.integrate as si\n",
    "\n",
    "def do_integrate(func):\n",
    "  \"\"\"\n",
    "  Integrate the given function from 1.0 to +inf.\n",
    "  \"\"\"\n",
    "  return si.quad(func, 1, np.inf)\n",
    "\n",
    "\n",
    "%timeit do_integrate(integrand)\n",
    "%timeit do_integrate(nb_integrand.ctypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "colab_type": "code",
    "id": "mxjzxr7y6Z-m",
    "outputId": "e71d63e6-4dbe-44b9-cbb0-6deedca9d608"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed (with compilation) = 0.2383380729999942\n",
      "Elapsed (after compilation) = 0.04302575799999886\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAAD8CAYAAABTjp5OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "@jit(nopython=True)\n",
    "def mandel(x, y, max_iters):\n",
    "    \"\"\"\n",
    "    Given the real and imaginary parts of a complex number,\n",
    "    determine if it is a candidate for membership in the Mandelbrot\n",
    "    set given a fixed number of iterations.\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    c = complex(x,y)\n",
    "    z = 0.0j\n",
    "    for i in range(max_iters):\n",
    "        z = z*z + c\n",
    "        if (z.real*z.real + z.imag*z.imag) >= 4:\n",
    "            return i\n",
    "    return 255\n",
    "\n",
    "\n",
    "@jit(nopython=True)  \n",
    "def julia(x, y, max_iters):\n",
    "    \"\"\"\n",
    "    Given the real and imaginary parts of a complex number,\n",
    "    determine if it is a candidate for membership in the Julia\n",
    "    set given a fixed number of iterations.\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    c = complex(-0.8, 0.156)\n",
    "    a = complex(x,y)\n",
    "    for i in range(max_iters):\n",
    "        a = a*a + c\n",
    "        if (a.real*a.real + a.imag*a.imag) > 1000:\n",
    "            return 0\n",
    "    return 255\n",
    "  \n",
    "\n",
    "@jit(nopython=True)\n",
    "def create_fractal(min_x, max_x, min_y, max_y, image, iters):\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "\n",
    "    pixel_size_x = (max_x - min_x) / width\n",
    "    pixel_size_y = (max_y - min_y) / height\n",
    "    for x in range(width):\n",
    "        real = min_x + x * pixel_size_x\n",
    "        for y in range(height):\n",
    "            imag = min_y + y * pixel_size_y\n",
    "            #color = mandel(real, imag, iters)\n",
    "            color = julia(real, imag, iters)\n",
    "            image[y, x] = color\n",
    "\n",
    "    return image\n",
    "\n",
    "image = np.zeros((500, 750), dtype=np.uint8)\n",
    "start = timer()\n",
    "create_fractal(-2.0, 2.0, -1.0, 1.0, image, 200)\n",
    "end = timer()\n",
    "print(\"Elapsed (with compilation) = %s\" % (end - start))\n",
    "start = timer()\n",
    "create_fractal(-2.0, 2.0, -1.0, 1.0, image, 200)\n",
    "end = timer()\n",
    "print(\"Elapsed (after compilation) = %s\" % (end - start))\n",
    "plt.imshow(image)\n",
    "plt.viridis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "FtUgga219nOi",
    "outputId": "f2ea927a-db1f-4462-e89d-384e454120ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda-10.0/nvvm/libdevice\n",
      "/usr/local/cuda-10.0/nvvm/lib64/libnvvm.so\n"
     ]
    }
   ],
   "source": [
    "!find / -iname 'libdevice'\n",
    "!find / -iname 'libnvvm.so'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WSPm1Q24ghFs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_fupor2b9xQD"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['NUMBAPRO_LIBDEVICE'] = \"/usr/local/cuda-10.0/nvvm/libdevice\"\n",
    "os.environ['NUMBAPRO_NVVM'] = \"/usr/local/cuda-10.0/nvvm/lib64/libnvvm.so\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "6dEE98r_gJPg",
    "outputId": "2c789641-35b9-4fe0-af0c-3b9c46030f23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [2 2 2 2 2 2 2 2 2 2]\n",
      " [3 3 3 3 3 3 3 3 3 3]\n",
      " [4 4 4 4 4 4 4 4 4 4]]\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "\n",
    "@cuda.jit\n",
    "def hello(data):\n",
    "    data[cuda.blockIdx.x, cuda.threadIdx.x] = cuda.blockIdx.x\n",
    "\n",
    "numBlocks = 5\n",
    "threadsPerBlock = 10\n",
    "\n",
    "data = np.ones((numBlocks, threadsPerBlock), dtype=np.uint8)\n",
    "\n",
    "hello[numBlocks, threadsPerBlock](data)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ACMUF50dZFKa"
   },
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def max_example(result, values):\n",
    "    \"\"\"Find the maximum value in values and store in result[0]\"\"\"\n",
    "    tid = cuda.threadIdx.x\n",
    "    bid = cuda.blockIdx.x\n",
    "    bdim = cuda.blockDim.x\n",
    "    i = (bid * bdim) + tid\n",
    "    cuda.atomic.max(result, 0, values[i])\n",
    "\n",
    "\n",
    "arr = np.random.rand(16384)\n",
    "result = np.zeros(1, dtype=np.float64)\n",
    "\n",
    "max_example[256,64](result, arr)\n",
    "print(result[0]) # Found using cuda.atomic.max\n",
    "print(max(arr))  # Print max(arr) for comparision (should be equal!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WdYvcSG_KvXn"
   },
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def compute_pi(rng_states, iterations, out):\n",
    "    \"\"\"Find the maximum value in values and store in result[0]\"\"\"\n",
    "    thread_id = cuda.grid(1)\n",
    "\n",
    "    # Compute pi by drawing random (x, y) points and finding what\n",
    "    # fraction lie inside a unit circle\n",
    "    inside = 0\n",
    "    for i in range(iterations):\n",
    "        x = xoroshiro128p_uniform_float32(rng_states, thread_id)\n",
    "        y = xoroshiro128p_uniform_float32(rng_states, thread_id)\n",
    "        if x**2 + y**2 <= 1.0:\n",
    "            inside += 1\n",
    "\n",
    "    out[thread_id] = 4.0 * inside / iterations\n",
    "\n",
    "threads_per_block = 64\n",
    "blocks = 24\n",
    "rng_states = create_xoroshiro128p_states(threads_per_block * blocks, seed=1)\n",
    "out = np.zeros(threads_per_block * blocks, dtype=np.float32)\n",
    "\n",
    "compute_pi[blocks, threads_per_block](rng_states, 10000, out)\n",
    "print('pi:', out.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_d8QGQioaKgF"
   },
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def matmul(A, B, C):\n",
    "    \"\"\"Perform square matrix multiplication of C = A * B\n",
    "    \"\"\"\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < C.shape[0] and j < C.shape[1]:\n",
    "        tmp = 0.\n",
    "        for k in range(A.shape[1]):\n",
    "            tmp += A[i, k] * B[k, j]\n",
    "        C[i, j] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hybeRDQ6aLdq"
   },
   "outputs": [],
   "source": [
    "from numba import cuda, float32\n",
    "\n",
    "# Controls threads per block and shared memory usage.\n",
    "# The computation will be done on blocks of TPBxTPB elements.\n",
    "TPB = 16\n",
    "\n",
    "@cuda.jit\n",
    "def fast_matmul(A, B, C):\n",
    "    # Define an array in the shared memory\n",
    "    # The size and type of the arrays must be known at compile time\n",
    "    sA = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
    "    sB = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
    "\n",
    "    x, y = cuda.grid(2)\n",
    "\n",
    "    tx = cuda.threadIdx.x\n",
    "    ty = cuda.threadIdx.y\n",
    "    bpg = cuda.gridDim.x    # blocks per grid\n",
    "\n",
    "    if x >= C.shape[0] and y >= C.shape[1]:\n",
    "        # Quit if (x, y) is outside of valid C boundary\n",
    "        return\n",
    "\n",
    "    # Each thread computes one element in the result matrix.\n",
    "    # The dot product is chunked into dot products of TPB-long vectors.\n",
    "    tmp = 0.\n",
    "    for i in range(bpg):\n",
    "        # Preload data into shared memory\n",
    "        sA[tx, ty] = A[x, ty + i * TPB]\n",
    "        sB[tx, ty] = B[tx + i * TPB, y]\n",
    "\n",
    "        # Wait until all threads finish preloading\n",
    "        cuda.syncthreads()\n",
    "\n",
    "        # Computes partial product on the shared memory\n",
    "        for j in range(TPB):\n",
    "            tmp += sA[tx, j] * sB[j, ty]\n",
    "\n",
    "        # Wait until all threads finish computing\n",
    "        cuda.syncthreads()\n",
    "\n",
    "    C[x, y] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "znihQVvqP73L"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from numba import cuda\n",
    "\n",
    "@cuda.reduce\n",
    "def sum_reduce(a, b):\n",
    "    return a + b\n",
    "\n",
    "A = (numpy.arange(1234, dtype=numpy.float64)) + 1\n",
    "expect = A.sum()      # numpy sum reduction\n",
    "got = sum_reduce(A)   # cuda sum reduction\n",
    "assert expect == got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JwOCO-tjQTYN"
   },
   "outputs": [],
   "source": [
    "from numba import vectorize, cuda\n",
    "\n",
    "# define a device function\n",
    "@cuda.jit('float32(float32, float32, float32)', device=True, inline=True)\n",
    "def cu_device_fn(x, y, z):\n",
    "    return x ** y / z\n",
    "\n",
    "# define a ufunc that calls our device function\n",
    "@vectorize(['float32(float32, float32, float32)'], target='cuda')\n",
    "def cu_ufunc(x, y, z):\n",
    "    return cu_device_fn(x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,N):\n",
    "    A[i] = A[i-1] * 2"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "numba_examples.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
