{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpu_intro.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evaneschneider/parallel-programming/blob/master/gpu_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "QicF_avFwaKK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Introduction to GPU programming with Numba"
      ]
    },
    {
      "metadata": {
        "id": "ZfMrCWC-N_7S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook borrows *heavily* from [seibert's 2018 gtc numba tutorial](https://github.com/ContinuumIO/gtc2018-numba). I highly recommend that tutorial in its entireity if you want more practice with Numba and GPUs."
      ]
    },
    {
      "metadata": {
        "id": "ePRO1HsDwkp2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Yesterday we discussed the principles of parallel programming, and explored the key aspects of using Numba - the `@jit` decorator, benchmarking, and the `@vectorize` decorator for Numpy UFuncs. Today we are going to expand on that basis and use Numba to do parallel calculations in python by taking advantage of Numba's GPU interface (and Google's free GPUs - thanks Colaboratory!)."
      ]
    },
    {
      "metadata": {
        "id": "x5CRqd4awPqx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "from numba import vectorize, cuda\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "drQnGa0vfCha",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Problem 0 - Accessing the GPU\n",
        "\n",
        "**0a)** In order to run Numba functions using the GPU, we have to do a couple of things. First, go to the Runtime menu, click on 'Change Runtime Type', and in the pop-up box, under 'Hardware Accelerator', select 'GPU'. Save the Runtime.\n",
        "\n",
        "**0b)** Ideally, that's all we should have to do. But in practice, even though the Cuda libararies are installed, for some reason Colab usually can't find them. So, we'll just figure out where they are, and then point Colab to them."
      ]
    },
    {
      "metadata": {
        "id": "qYzz2fEegbpG",
        "colab_type": "code",
        "outputId": "f433cae0-95ed-4c18-a948-495e4350f975",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!find / -iname 'libdevice'\n",
        "!find / -iname 'libnvvm.so'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/cuda-10.0/nvvm/libdevice\n",
            "/usr/local/cuda-10.0/nvvm/lib64/libnvvm.so\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PqW3vHXPgjqk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Paste the location of the libraries into the following code box (if it's different, otherwise you can just run the code):"
      ]
    },
    {
      "metadata": {
        "id": "na0O3h9hgoVa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['NUMBAPRO_LIBDEVICE'] = \"/usr/local/cuda-10.0/nvvm/libdevice\"\n",
        "os.environ['NUMBAPRO_NVVM'] = \"/usr/local/cuda-10.0/nvvm/lib64/libnvvm.so\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g007BPp8fHtO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And that should do it! Okay, now that we've pointed Numba to the correct libraries, let's get going. To start, we are going to return to the simplest function we created yesterday - the vector add."
      ]
    },
    {
      "metadata": {
        "id": "JV9ELUHwxnZh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Problem 1 - Vector Addition on GPUs"
      ]
    },
    {
      "metadata": {
        "id": "1veva5o3sYB4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The simplest way to access the GPU through Numba is to return to our vectorized ufunc from yesterday. As you may recall, Numpy Universal Functions operate on vectors, or arrays. If we specify the `cuda` target, Numba will automatically write a Cuda kernel for us, and run the function on the GPU! Let's try it out:"
      ]
    },
    {
      "metadata": {
        "id": "Klw3GHXtwWyW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "@vectorize(['int64(int64, int64)'], target='cuda')\n",
        "def add_ufunc(x, y):\n",
        "    return x + y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b9UKqsW7gOda",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a = np.arange(n)\n",
        "b = 2 * a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NGQhcF7xtT-B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ff5acf90-ac8c-49ce-edf6-d8f76b784d6a"
      },
      "cell_type": "code",
      "source": [
        "add_ufunc(a,b)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([     0,      3,      6, ..., 299991, 299994, 299997])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "noAuRtx_tpil",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Cool, it worked! But what actually just happened? Well, a lot of things. Numba automatically:\n",
        "+ Compiled a CUDA kernel to execute the ufunc operation in parallel over all the input elements.\n",
        "+ Allocated GPU memory for the inputs and the output.\n",
        "+ Copied the input data to the GPU.\n",
        "+ Executed the CUDA kernel with the correct kernel dimensions given the input sizes.\n",
        "+ Copied the result back from the GPU to the CPU.\n",
        "+ Returned the result as a NumPy array on the host."
      ]
    },
    {
      "metadata": {
        "id": "Kw7gZF1muGpy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**1a)** Determine how fast the cuda addition function is. Compare that to a function compiled for the CPU. How does the GPU do?"
      ]
    },
    {
      "metadata": {
        "id": "ZKCwRcCEtXcd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "77e2f78d-6ff0-4ba0-bf19-1ac457dccafb"
      },
      "cell_type": "code",
      "source": [
        "%timeit add_ufunc(a,b) # add code here"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 loops, best of 3: 2.59 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AkMt5Fy0ugRm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**1b)** Wow, the GPU is a LOT slower! Why might that be?"
      ]
    },
    {
      "metadata": {
        "id": "g8BsBv1_uzqM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Answer: We have (deliberately) misused the GPU in several ways in this example:\n",
        "+ **Our inputs are too small**: the GPU achieves performance through parallelism, operating on thousands of values at once. Our test inputs have only 10 integers. We need a much larger array to even keep the GPU busy.\n",
        "+ **Our calculation is too simple**: Sending a calculation to the GPU involves quite a bit of overhead compared to calling a function on the CPU. If our calculation does not involve enough math operations (\"arithmetic intensity\"), then the GPU will spend most of its time waiting for data to move around.\n",
        "+ **We copy the data to and from the GPU**: While including the copy time can be realistic for a single function, often we want to run several GPU operations in sequence. In those cases, it makes sense to send data to the GPU and keep it there until all of our processing is complete.\n",
        "+ **Our data types are larger than necessary**: Our example uses int64 when we probably don't need it. Scalar code using data types that are 32 and 64-bit run basically the same speed on the CPU, but 64-bit data types have a significant performance cost on the GPU. Basic arithmetic on 64-bit floats can be anywhere from 2x (Pascal-architecture Tesla) to 24x (Maxwell-architecture GeForce) slower than 32-bit floats. NumPy defaults to 64-bit data types when creating arrays, so it is important to set the dtype attribute or use the ndarray.astype() method to pick 32-bit types when you need them.\n"
      ]
    },
    {
      "metadata": {
        "id": "FJVE9XZSQSMj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Problem 2 - Memory Management\n",
        "\n",
        "As we saw in the last problem, Numba can automatically handle transferring data to and from the GPU for us. However, that's not always what we want. Sometimes we will want to perform several functions in a row on the GPU without transferring the data back to the CPU in between."
      ]
    },
    {
      "metadata": {
        "id": "ZltkamG0KFYv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**2a)** Remake the addition ufunc to operate on and return 32 bit floats"
      ]
    },
    {
      "metadata": {
        "id": "OqWl14DCKKso",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "@vectorize(['float32(float32, float32)'], target='cuda') # add code here\n",
        "def add_ufunc(x, y):\n",
        "    return x + y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8-ZpffA3KoV1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, let's give it a bit more work to do:"
      ]
    },
    {
      "metadata": {
        "id": "dS1dCw0PKTdj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n = 100000\n",
        "x = np.arange(n).astype(np.float32)\n",
        "y = 2 * x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ABw7nZWFKs7b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As we saw in the last problem, copying the data to and from the GPU for every function is not necessarily the most efficient way to use the GPU. To address this, Numba provides function in the cuda module to allocate and copy arrays to the GPU:"
      ]
    },
    {
      "metadata": {
        "id": "p3eu33UFuVfM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5d34a9e5-bcdb-480e-d66d-90ec06e33da8"
      },
      "cell_type": "code",
      "source": [
        "x_device = cuda.to_device(x)\n",
        "y_device = cuda.to_device(y)\n",
        "\n",
        "print(x_device)\n",
        "print(x_device.shape)\n",
        "print(x_device.dtype)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<numba.cuda.cudadrv.devicearray.DeviceNDArray object at 0x7f1ca795f6a0>\n",
            "(100000,)\n",
            "float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "f5U0-goyLG7t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "`x_device` and `y_device` are now Numba \"device arrays\" that are in many ways equivalent to Numpy ndarrays except that they live in the GPU's global memory, rather than on the CPU. These device arrays can be passed to Numba cuda functions just the way Numpy arrays can, but without the memory copying overhead."
      ]
    },
    {
      "metadata": {
        "id": "QCF1pxsmLwJF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**2b)** Try out your function using host vs device arrays. How does the time compare?"
      ]
    },
    {
      "metadata": {
        "id": "JNJHfuSSMAf_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eef49413-ef85-4909-d839-5d165cbcc05b"
      },
      "cell_type": "code",
      "source": [
        "%timeit add_ufunc(x, y)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000 loops, best of 3: 1.81 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R9Y59-0zIUno",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "54fc5f7b-7b30-4cb8-c97c-4f21feabb458"
      },
      "cell_type": "code",
      "source": [
        "%timeit add_ufunc(x_device, y_device)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000 loops, best of 3: 1.02 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nhqU-TCKMQZB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "That's a big performance improvement already, but we are still allocating a device array for the output of the ufunc and copying it back to the host. We can create the output buffer with the numba.cuda.device_array() function:"
      ]
    },
    {
      "metadata": {
        "id": "ShhIJX80L_Qh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "out_device = cuda.device_array(shape=(n,), dtype=np.float32)  # does not initialize the contents, much like np.empty()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T4B1aBILMc_E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And then we can use a special out keyword argument to the ufunc to specify the output buffer:"
      ]
    },
    {
      "metadata": {
        "id": "umP9Ab7YMY8H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c78d477f-ab09-4090-a9ae-db9c90fb82d8"
      },
      "cell_type": "code",
      "source": [
        "%timeit add_ufunc(x_device, y_device, out=out_device)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 7.36 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "1000 loops, best of 3: 747 Âµs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hhF9NpXONd5E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we're cooking with gas! Once we've finished all of our calculations on the GPU, we can copy the array back from the device using the `copy_to_host` method:"
      ]
    },
    {
      "metadata": {
        "id": "8QAMR4qKMgoS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "176c361c-9573-44ef-b627-4f45955645c4"
      },
      "cell_type": "code",
      "source": [
        "out_host = out_device.copy_to_host()\n",
        "print(out_host[:10])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.  3.  6.  9. 12. 15. 18. 21. 24. 27.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eeve4KxkO2OZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**2c)** Given these ufuncs:"
      ]
    },
    {
      "metadata": {
        "id": "5VeKgSFXNxxa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "@vectorize(['float32(float32, float32, float32)'], target='cuda')\n",
        "def make_pulses(i, period, amplitude):\n",
        "    return max(math.sin(i / period) - 0.3, 0.0) * amplitude\n",
        "\n",
        "n = 100000\n",
        "noise = (np.random.normal(size=n) * 3).astype(np.float32)\n",
        "t = np.arange(n, dtype=np.float32)\n",
        "period = n / 23"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PaAgMJf3PITJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Convert the following code to use device allocations so that there are only host<->device copies at the beginning and end. Then benchmark the performance change."
      ]
    },
    {
      "metadata": {
        "id": "EpDq3V6eO_CY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pulses = make_pulses(t, period, 100.0)\n",
        "waveform = add_ufunc(pulses, noise)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AbMU8BVfPUeO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "0e748ff6-3f48-4326-cf58-0fb8b8119948"
      },
      "cell_type": "code",
      "source": [
        "plt.plot(waveform)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f1ca78d0cf8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAD4CAYAAAAaT9YAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPZ8VAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "RNcWlpFWPhoz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}