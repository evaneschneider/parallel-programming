{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpu_intro.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evaneschneider/parallel-programming/blob/master/gpu_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "QicF_avFwaKK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Introduction to GPU programming with Numba"
      ]
    },
    {
      "metadata": {
        "id": "ePRO1HsDwkp2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Yesterday we discussed the principles of parallel programming, and explored the key aspects of using Numba - the `@jit` decorator, benchmarking, and the `@vectorize` decorator for Numpy UFuncs. Today we are going to expand on that basis and use Numba to do parallel calculations in python by taking advantage of Numba's GPU interface (and Google's free GPUs - thanks colab!)."
      ]
    },
    {
      "metadata": {
        "id": "x5CRqd4awPqx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numba import cuda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "drQnGa0vfCha",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Problem 0 - Accessing the GPU\n",
        "\n",
        "**0a)** In order to run Numba functions using the GPU, we have to do a couple of things. First, go to the Runtime menu, click on 'Change Runtime Type', and in the pop-up box, under 'Hardware Accelerator', select 'GPU'. Save the Runtime.\n",
        "\n",
        "**0b)** Ideally, that's all we should have to do. But in practice, even thought the Cuda libararies are installed, for some reason Colab usually can't find them. So, we'll just figure out where they are, and then point Colab to them."
      ]
    },
    {
      "metadata": {
        "id": "qYzz2fEegbpG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f80bd731-83ad-44bd-f744-d3bd5373328c"
      },
      "cell_type": "code",
      "source": [
        "!find / -iname 'libdevice'\n",
        "!find / -iname 'libnvvm.so'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/cuda-10.0/nvvm/libdevice\n",
            "/usr/local/cuda-10.0/nvvm/lib64/libnvvm.so\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PqW3vHXPgjqk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Paste the location of the libraries into the following code box:"
      ]
    },
    {
      "metadata": {
        "id": "na0O3h9hgoVa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['NUMBAPRO_LIBDEVICE'] = \"/usr/local/cuda-10.0/nvvm/libdevice\"\n",
        "os.environ['NUMBAPRO_NVVM'] = \"/usr/local/cuda-10.0/nvvm/lib64/libnvvm.so\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g007BPp8fHtO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And that should do it! Okay, now that we've pointed Numba to the correct libraries, let's get going. To start, we are going to return to the simplest function we created yesterday - the vector add."
      ]
    },
    {
      "metadata": {
        "id": "JV9ELUHwxnZh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Problem 1 - Vector Addition on GPUs"
      ]
    },
    {
      "metadata": {
        "id": "Klw3GHXtwWyW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "8b8b1b8d-585b-4840-f386-a3f74f51a308"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [1 1 1 1 1 1 1 1 1 1]\n",
            " [2 2 2 2 2 2 2 2 2 2]\n",
            " [3 3 3 3 3 3 3 3 3 3]\n",
            " [4 4 4 4 4 4 4 4 4 4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b9UKqsW7gOda",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}